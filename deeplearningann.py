# -*- coding: utf-8 -*-
"""DeepLearningANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Acm-fzRYuiOxxfP3vfs4OqQGQujM14P8

## STUDI KASUS
Jika mengetahui pelanggan yang berkemungkinan berhenti menggunakan layanan bank, kita dapat memberikan penawaran yang lebih baik kepada nasabah ini. kita memiliki sampel dataset dari bank yang berjumlah 2000 nasabah. Selanjutnya kita akan memprediksi nasabah yang akan berhenti melakukan transaksi perbankan dengan bank ini.

### Importing library
"""

import numpy as np
import pandas as pd
import tensorflow as tf

tf.__version__

"""## Part 1 - Data Preprocessing

### Importing dataset
"""

dataset = pd.read_csv('/content/Churn_Modelling.csv')
dataset.head()

"""Menyingkirkan Atribut yang useless / tidak berguna seperti row number, customer id, and customer names karena tidak akan membantu untuk memprediksi nasabah yang akan keluar dari bank."""

X = dataset.iloc[:, 3:-1].values
y = dataset.iloc[:, -1].values

"""cetak variabel independen"""

print(X)

"""Cetak variabel dependen"""

print(y)

"""### Encoding categorical data

Bisa di perhatikan bahwa ada beberapa variabel kategorikal yaitu gender dan geography. Untuk variabel geography kita akan mengubah variabel tersebut menjadi biner melalui proses one-hote-encode dengan menambah kolom baru di dalam dataset, sebagai contoh 1, 0, 0 akan merepresentasikan nasabah dari France.
 
Untuk variabel gender kita akan mengubah variabel tersebut menjadi numerik, sebagai contoh 0 akan direpresentasikan perempuan dan 1 akan merepresentasikan laki-laki.

Label Encoding the "Gender" column
"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
X[:, 2] = le.fit_transform(X[:, 2])

print(X)

"""One Hot Encoding the "Geography" column"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')
X = np.array(ct.fit_transform(X))

print(X)

"""### Splitting the dataset into the Training set and Test set

Selanjutnya kita akan membagi dataset menjadi 2 yaitu training dan testing. Sebanyak 80%(test_size=0.2) dataset akan digunakan untuk training, random state = 0 untuk memperoleh dataset yang sama saat dibagi.
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""### Feature Scaling

Selanjutnya kita akan melakukan feature scaling untuk menormalisasi semua variabel independen. Hal ini dilakukan untuk mereduksi waktu pada saat training dilakukan.
"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

print(X_train)

# get number of input 
X_train[0].shape

"""## Part 2 - Building the ANN

### Initializing the ANN

Kita akan membangun neural network dengan kelas Sequential() . langkah pertama adalah membuat layer input dengan 12 node. 12 adalah jumlah baris dalam training set. selanjutnya kita menambahkan hidden layer.
"""

ann = tf.keras.models.Sequential()

"""### Adding the input layer and the first hidden layer"""

ann.add(tf.keras.layers.Dense(units=12, activation='relu', input_shape=X_train[0].shape, name='layer_1'))

"""### Adding the second hidden layer"""

ann.add(tf.keras.layers.Dense(units=8, activation='relu', name='layer_2'))

"""### Adding the output layer"""

ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid', name='Layer_terakhir'))

"""Kita dapat melihat nilai dari weight dan bias pada neuron tiap-tiap layer

---


"""

print("Bobot dan bias tiap layer: \n")
for layer in ann.layers:
  print(layer.name)
  print("Bobot")
  print("Shape: ",layer.get_weights()[0].shape,'\n',layer.get_weights()[0])
  print("Bias")
  print("Shape: ",layer.get_weights()[1].shape,'\n',layer.get_weights()[1],'\n')

"""Visualisasi model yang telah dibuat"""

from tensorflow.keras.utils import plot_model
plot_model(ann,
          to_file="model.png",
          show_shapes=True,
          show_layer_names=True,
          )

"""## Part 3 - Training the ANN

Dalam Training ANN, kita akan melakukan beberapa tugas antara lain:
1. kita meng'compile' model dengan Adam oprimizer untuk menemukan weight yang optimal.
2. kita menggunakan binary_crossentropy loss.
3. kita melatih model selama 100 epoch.

### Compiling the ANN
"""

ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

"""### Training the ANN on the Training set

batch_size 32(default) menunjukkan jumlah sampel yang diproses sebelum model ANN diperbarui. 1 epoch selesai ketika seluruh dataset diteruskan maju dan mundur melalui neural network satu kali.
"""

ann.fit(X_train, y_train, batch_size = 32, epochs = 100)

print("Weigh dan bias tiap layer: \n")
for layer in ann.layers:
  print(layer.name)
  print("Bobot")
  print("Shape: ",layer.get_weights()[0].shape,'\n',layer.get_weights()[0])
  print("Bias")
  print("Shape: ",layer.get_weights()[1].shape,'\n',layer.get_weights()[1],'\n')

"""## Part 4 - Making the predictions and evaluating the model

training model telah dilakukan, selanjutnya kita dapat membuat prediksi pada satu nasabah. Detail data nasabah yang akan kita uji adalah sbb:

Geography: Spain

Credit Score: 600

Gender: Male

Age: 40 years old

Tenure: 3 years

Balance: $ 60000

Number of Products: 2

Does this customer have a credit card ? Yes

Is this customer an Active Member: Yes

Estimated Salary: $ 50000

Jadi apakah nasabah tersebut berkemungkinan akan berhenti menggunakan layanan bank?

### Predicting the result of a single observation

Jika hasilnya 0, maka nasabah tidak/kurang peluang untuk berhenti menggunakan layanan bank. Jika hasilnya 1, nasabah memiliki kemungkinan lebih tinggi untuk berhenti menggunakan layanan bank. Hasil kita adalah 0,03, yang mendekati nol, jadi berkemungkinan besar nasabah akan tetap menggunakan layanan bank.
"""

print(ann.predict(sc.transform([[0, 0, 1, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))

"""Selanjutnya Kita dapat menambahkan ambang batas 0,5. Nasabah akan meninggalkan bank jika probabilitas yang diprediksi di atas 0,5."""

print(ann.predict(sc.transform([[0, 0, 1, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)

"""### Predicting the Test set results"""

y_pred = ann.predict(X_test)
y_pred = (y_pred > 0.5)
pd.DataFrame(list(zip(y_test, y_pred)), columns=['Nilai Sebenarnya', 'Prediksi'])

"""### Making the Confusion Matrix"""

from sklearn.metrics import confusion_matrix, accuracy_score
print(confusion_matrix(y_test, y_pred))
print(accuracy_score(y_test, y_pred))